{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60bdd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import glob\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cdb9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'dataset'\n",
    "categories = ['Acne', 'Blackheads', 'Dark Spots', 'Normal Skin', 'Oily Skin', 'Wrinkles']\n",
    "img_size = 224\n",
    "BATCH_SIZE = 64\n",
    "num_classes = len(categories)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fc68d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2\n",
    ")\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ea9a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mapping folder ke label (class_indices):\", train_gen.class_indices)\n",
    "print(\"Urutan categories:\", categories)\n",
    "print(\"Distribusi label di data training:\", np.bincount(train_gen.classes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a429999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_gen.classes),\n",
    "    y=train_gen.classes\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a38e40e",
   "metadata": {},
   "source": [
    "15. Siapkan daftar file & label, split stratified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a45b87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Gunakan variabel yang sudah ada: dataset_path, categories, img_size, BATCH_SIZE\n",
    "# Hanya gunakan format yang didukung decoder TensorFlow: JPEG, PNG, BMP, GIF\n",
    "image_exts = (\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\", \"*.gif\")\n",
    "\n",
    "filepaths = []\n",
    "labels = []\n",
    "for cls_idx, cls_name in enumerate(categories):\n",
    "    cls_dir = os.path.join(dataset_path, cls_name)\n",
    "    cls_files = []\n",
    "    for ext in image_exts:\n",
    "        cls_files.extend(glob.glob(os.path.join(cls_dir, ext)))\n",
    "    # Tambahkan ke list global\n",
    "    filepaths += cls_files\n",
    "    labels += [cls_idx] * len(cls_files)\n",
    "\n",
    "# Filter defensif: pastikan ekstensi valid (hindari file non-gambar)\n",
    "valid_suffix = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\")\n",
    "filtered = [(fp, lab) for fp, lab in zip(filepaths, labels) if fp.lower().endswith(valid_suffix)]\n",
    "filepaths = [fp for fp, _ in filtered]\n",
    "labels = [lab for _, lab in filtered]\n",
    "\n",
    "# Split stratified untuk train/valid (20% validasi)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    filepaths, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# Tampilkan ringkas distribusi sebelum balancing\n",
    "import numpy as np\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(\"Distribusi train sebelum balancing:\")\n",
    "for u, c in zip(unique, counts):\n",
    "    print(f\"  {categories[u]}: {c}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb97693",
   "metadata": {},
   "source": [
    "16. Bangun tf.data untuk oversampling per-kelas (robust decoding via PIL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62975ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Decoder robust menggunakan PIL agar mendukung lebih banyak format dan menghindari crash\n",
    "def pil_decode_and_resize(path):\n",
    "    path_str = path.numpy().decode(\"utf-8\")\n",
    "    with Image.open(path_str) as img:\n",
    "        img = img.convert(\"RGB\")\n",
    "        img = img.resize((img_size, img_size))\n",
    "        arr = np.asarray(img, dtype=np.float32)\n",
    "        return arr\n",
    "\n",
    "def _load_and_preprocess(path, label):\n",
    "    # Gunakan tf.py_function untuk memanggil PIL\n",
    "    img = tf.py_function(func=pil_decode_and_resize, inp=[path], Tout=tf.float32)\n",
    "    # Set shape statis agar Keras tahu dimensi\n",
    "    img = tf.reshape(img, [img_size, img_size, 3])\n",
    "    # MobileNetV2 preprocessing\n",
    "    img = preprocess_input(img)\n",
    "    return img, label\n",
    "\n",
    "# Dataset validasi (tanpa oversampling)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "val_ds = val_ds.map(_load_and_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "# Dataset per-kelas untuk train\n",
    "per_class_datasets = []\n",
    "class_counts = []\n",
    "for cls_idx, cls_name in enumerate(categories):\n",
    "    cls_files = [fp for fp, lab in zip(X_train, y_train) if lab == cls_idx]\n",
    "    class_counts.append(len(cls_files))\n",
    "    ds = tf.data.Dataset.from_tensor_slices((cls_files, [cls_idx] * len(cls_files)))\n",
    "    ds = ds.shuffle(max(8*BATCH_SIZE, len(cls_files)))\n",
    "    ds = ds.repeat()  # penting agar sampler bisa menarik elemen terus-menerus\n",
    "    ds = ds.map(_load_and_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    per_class_datasets.append(ds)\n",
    "\n",
    "# Bobot sampling: seimbangkan kelas (semua sama besar)\n",
    "num_classes = len(categories)\n",
    "weights = [1.0/num_classes] * num_classes\n",
    "\n",
    "balanced_ds = tf.data.experimental.sample_from_datasets(per_class_datasets, weights=weights)\n",
    "train_ds_balanced = balanced_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "print(\"Oversampling aktif. Batch train akan berisi distribusi kelas ~seimbang. Decoder: PIL.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5952d36",
   "metadata": {},
   "source": [
    "Transfer Learning Model (MobileNetV2 + Decision Layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d53709",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(\n",
    "    input_shape=(img_size, img_size, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8d265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(img_size, img_size, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs, outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7794ec05",
   "metadata": {},
   "source": [
    "7. Callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde26dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_skin_model.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c00a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34eb489",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db1996a",
   "metadata": {},
   "source": [
    "17. Latih model menggunakan dataset seimbang (tanpa class_weight)\n",
    "Pastikan model, callbacks (early_stopping, checkpoint, reduce_lr) sudah didefinisikan sebelumnya.\n",
    "Tentukan steps_per_epoch (jumlah batch per epoch) karena train_ds_balanced.repeat() bersifat tak terbatas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606ae69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "steps_per_epoch = max(1, sum(class_counts) // BATCH_SIZE)\n",
    "print(\"steps_per_epoch:\", steps_per_epoch)\n",
    "\n",
    "history_balanced = model.fit(\n",
    "    train_ds_balanced,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping, checkpoint, reduce_lr]\n",
    ")\n",
    "\n",
    "# Plot training curves (accuracy & loss) for balanced training\n",
    "def plot_training_history(history):\n",
    "    acc = history.history.get('accuracy', [])\n",
    "    val_acc = history.history.get('val_accuracy', [])\n",
    "    loss = history.history.get('loss', [])\n",
    "    val_loss = history.history.get('val_loss', [])\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(acc, label='Train Accuracy')\n",
    "    plt.plot(val_acc, label='Val Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(loss, label='Train Loss')\n",
    "    plt.plot(val_loss, label='Val Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history_balanced)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60553592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def load_and_preprocess_image(img_path, target_size=(224, 224)):\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    img_array = tf.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "def predict_skin_condition(model, img_path, categories):\n",
    "    img_array = load_and_preprocess_image(img_path)\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = tf.argmax(predictions, axis=1).numpy()[0]\n",
    "    confidence = float(np.max(predictions)) * 100\n",
    "    return predicted_class, categories[predicted_class], confidence\n",
    "\n",
    "def show_recommendations(predicted_label):\n",
    "    df = pd.read_csv('skincare_product/treatment.csv')\n",
    "    produk = df[df['Tags'].str.lower() == predicted_label.lower()]\n",
    "    if produk.empty:\n",
    "        print(\"Tidak ada rekomendasi produk untuk kategori ini.\")\n",
    "        return\n",
    "    print(f\"\\nRekomendasi produk untuk '{predicted_label}':\")\n",
    "    for _, row in produk.iterrows():\n",
    "        print(f\"- {row['Brand']} | {row['Product Name']} | {row['Price']}\")\n",
    "        print(f\"  Link: {row['Links']}\")\n",
    "        # Cek semua kemungkinan ekstensi gambar\n",
    "        img_found = False\n",
    "        for ext in ['png', 'jpg', 'jpeg', 'webp']:\n",
    "            img_path = f\"skincare_product/gambar_produk/{row['Id']}.{ext}\"\n",
    "            if os.path.exists(img_path):\n",
    "                img_prod = image.load_img(img_path, target_size=(720, 1280))\n",
    "                plt.figure()\n",
    "                plt.imshow(img_prod)\n",
    "                plt.title(f\"{row['Brand']} - {row['Product Name']}\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "                img_found = True\n",
    "                break\n",
    "        if not img_found:\n",
    "            # Jika tidak ditemukan, coba cari dengan glob (jaga-jaga ada nama file aneh)\n",
    "            pattern = f\"skincare_product/gambar_produk/{row['Id']}.*\"\n",
    "            matches = glob.glob(pattern)\n",
    "            if matches:\n",
    "                img_prod = image.load_img(matches[0], target_size=(720, 1280))\n",
    "                plt.figure()\n",
    "                plt.imshow(img_prod)\n",
    "                plt.title(f\"{row['Brand']} - {row['Product Name']}\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(f\"  Gambar produk tidak ditemukan untuk ID: {row['Id']}\")\n",
    "\n",
    "# Contoh penggunaan prediksi gambar baru\n",
    "img_path = \"darkspot.jpg\"  # Ganti dengan path gambar yang ingin diuji\n",
    "if os.path.exists(img_path):\n",
    "    predicted_class_index, predicted_class_name, confidence = predict_skin_condition(model, img_path, categories)\n",
    "    print(f\"Predicted class index: {predicted_class_index}\")\n",
    "    print(f\"Predicted class name: {predicted_class_name}\")\n",
    "    print(f\"Confidence: {confidence:.2f}%\")\n",
    "    img_disp = image.load_img(img_path, target_size=(720, 1280))\n",
    "    plt.imshow(img_disp)\n",
    "    plt.title(f\"Predicted: {predicted_class_name} ({confidence:.2f}%)\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    show_recommendations(predicted_class_name)\n",
    "else:\n",
    "    print(f\"File {img_path} tidak ditemukan.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463a0e6c",
   "metadata": {},
   "source": [
    "18. Evaluasi: Confusion Matrix & Classification Report pada validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5212d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEvaluasi pada validation set (confusion matrix & classification report)...\")\n",
    "\n",
    "# Kumpulkan prediksi pada val_ds\n",
    "y_true = np.array(y_val)\n",
    "y_pred = []\n",
    "for batch_imgs, _ in val_ds:\n",
    "    probs = model.predict(batch_imgs, verbose=0)\n",
    "    batch_pred = np.argmax(probs, axis=1)\n",
    "    y_pred.extend(batch_pred)\n",
    "y_pred = np.array(y_pred[:len(y_true)])  # jaga-jaga jika overshoot\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=categories, yticklabels=categories)\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Confusion Matrix (Validation)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()\n",
    "print(\"Confusion matrix disimpan ke 'confusion_matrix.png'.\")\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_true, y_pred, target_names=categories, digits=4)\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "with open('classification_report.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "print(\"Classification report disimpan ke 'classification_report.txt'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6709ae5",
   "metadata": {},
   "source": [
    "13. SIMPAN MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad01576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('best_skin_model.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217d0aee",
   "metadata": {},
   "source": [
    "14.EKSPOR MODEL KE ONNX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fe1443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf2onnx\n",
    "import onnx\n",
    "model = tf.keras.models.load_model('best_skin_model.h5')\n",
    "spec = (tf.TensorSpec((None, img_size, img_size, 3), tf.float32, name=\"input_1\"),)\n",
    "output_path = 'best_skin_model.onnx'\n",
    "model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, output_path=output_path)\n",
    "onnx.save_model(model_proto, output_path)\n",
    "print(f\"Model berhasil diekspor ke {output_path}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
